{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -q timm","metadata":{"execution":{"iopub.status.busy":"2022-11-21T14:21:04.419654Z","iopub.execute_input":"2022-11-21T14:21:04.420179Z","iopub.status.idle":"2022-11-21T14:21:16.684886Z","shell.execute_reply.started":"2022-11-21T14:21:04.420063Z","shell.execute_reply":"2022-11-21T14:21:16.683700Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"# with open('../input/zalo2022-livenessdetection-darknet53-fold-0/Fold0/log.txt', 'r') as f:\n#     content = f.read().split('\\n')\n    \n# content","metadata":{"execution":{"iopub.status.busy":"2022-11-21T14:21:16.687703Z","iopub.execute_input":"2022-11-21T14:21:16.688100Z","iopub.status.idle":"2022-11-21T14:21:16.693148Z","shell.execute_reply.started":"2022-11-21T14:21:16.688061Z","shell.execute_reply":"2022-11-21T14:21:16.692214Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"import os\nimport sys\nimport pandas as pd\nimport numpy as np\nimport torch\nfrom torch.utils.data import DataLoader as DataLoader\nfrom torch.utils.data import Dataset as Dataset\nimport cv2\nimport timm\n\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\nfrom tqdm import tqdm\nfrom torch.optim.lr_scheduler import ReduceLROnPlateau\n\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.metrics import roc_curve\nimport math\nimport gc\nimport time","metadata":{"execution":{"iopub.status.busy":"2022-11-21T14:21:16.694651Z","iopub.execute_input":"2022-11-21T14:21:16.695008Z","iopub.status.idle":"2022-11-21T14:21:20.943048Z","shell.execute_reply.started":"2022-11-21T14:21:16.694958Z","shell.execute_reply":"2022-11-21T14:21:20.942030Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"ckpt_path = '../input/zalo2022-livenessdetection-darknet53-fold-0/Fold0/best.pt'\nckpt = torch.load(ckpt_path)\nckpt.keys()","metadata":{"execution":{"iopub.status.busy":"2022-11-21T14:21:20.945633Z","iopub.execute_input":"2022-11-21T14:21:20.946579Z","iopub.status.idle":"2022-11-21T14:21:31.755940Z","shell.execute_reply.started":"2022-11-21T14:21:20.946541Z","shell.execute_reply":"2022-11-21T14:21:31.754923Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"dict_keys(['epoch', 'state_dict', 'train_loss', 'valid_loss', 'auc_score', 'eer', 'opti', 'scheduler'])"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"backbone = 'darknet53'\n# ROOT_DIR = '../input/yakiniku'\n# VIDEO_DIR = os.path.join(ROOT_DIR, 'train_new/train/videos')\n# CSV_PATH = os.path.join(ROOT_DIR, 'label_5folds.csv')\n# PUBLIC_TEST_PATH = os.path.join(ROOT_DIR, 'public_test/public/videos')\n\n# ROOT_DIR = '../input/zalo2022-pbl2'\n# VIDEO_DIR = os.path.join(ROOT_DIR, 'public_test_2/videos')\n# CSV_PATH = os.path.join(ROOT_DIR, 'label_5folds.csv')\n# PUBLIC_TEST_PATH = os.path.join(ROOT_DIR, 'public_test_2/videos/')\nPUBLIC_TEST_PATH = '../input/zalo2022-pbl2/public_test_2/public_test_2/videos'","metadata":{"execution":{"iopub.status.busy":"2022-11-21T14:21:31.760400Z","iopub.execute_input":"2022-11-21T14:21:31.762849Z","iopub.status.idle":"2022-11-21T14:21:31.769238Z","shell.execute_reply.started":"2022-11-21T14:21:31.762787Z","shell.execute_reply":"2022-11-21T14:21:31.767914Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# create sample submission\nsubmission = pd.DataFrame()\nfname_lst = []\npublic_test_files = os.listdir(PUBLIC_TEST_PATH)\nfor file in public_test_files:\n    if file.endswith('.mp4'):\n        fname_lst.append(file)\n        \nsubmission['fname'] = fname_lst","metadata":{"execution":{"iopub.status.busy":"2022-11-21T14:21:31.770427Z","iopub.execute_input":"2022-11-21T14:21:31.776619Z","iopub.status.idle":"2022-11-21T14:21:31.865573Z","shell.execute_reply.started":"2022-11-21T14:21:31.776592Z","shell.execute_reply":"2022-11-21T14:21:31.864486Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# config\nDEVICE = torch.device('cuda:0')\nEPOCHS = 50\nFOLD_LST = [0,1,2,3,4]\n# DIM = (320, 320)\nDIM = (384, 384)\n# DIM = (480, 480)\n# DIM = (224, 224)\nTRAIN_BATCH_SIZE = 16\n# VALID_BATCH_SIZE = 2 * TRAIN_BATCH_SIZE\nVALID_BATCH_SIZE = 1\nLR = 1e-4\nSAMPLE = None\n\nvalid_transform = A.Compose(\n    [\n        A.Resize(DIM[0], DIM[1], always_apply=True),\n        A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n        ToTensorV2()\n    ]\n)","metadata":{"execution":{"iopub.status.busy":"2022-11-21T14:21:31.870271Z","iopub.execute_input":"2022-11-21T14:21:31.873010Z","iopub.status.idle":"2022-11-21T14:21:31.883220Z","shell.execute_reply.started":"2022-11-21T14:21:31.872960Z","shell.execute_reply":"2022-11-21T14:21:31.882032Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"class LivenessDataset(Dataset):\n    def __init__(self, df, video_dir, take_frame = 5, transform=None):\n        self.df = df.reset_index(drop = True)\n        self.take_frame = take_frame\n        self.video_dir = video_dir\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        fname = self.df.iloc[idx]['fname']\n        video_path = os.path.join(self.video_dir, fname)\n        video = cv2.VideoCapture(video_path)\n        image_lst = []\n        frame_number = 0\n        length = int(video.get(cv2.CAP_PROP_FRAME_COUNT))\n        frame_step = length // self.take_frame\n        while video.isOpened():\n            ret, frame = video.read()\n            if ret:\n                frame_number += 1\n                if frame is not None and frame_number % frame_step == 0:\n                    if self.transform is not None:\n                        frame = self.transform(image=frame)[\"image\"]\n                    image_lst.append(frame)\n            else:\n                break\n        video.release()\n        image_lst = image_lst[:self.take_frame]\n        return torch.stack(image_lst, axis =0)","metadata":{"execution":{"iopub.status.busy":"2022-11-21T14:21:31.887801Z","iopub.execute_input":"2022-11-21T14:21:31.888703Z","iopub.status.idle":"2022-11-21T14:21:31.905129Z","shell.execute_reply.started":"2022-11-21T14:21:31.888663Z","shell.execute_reply":"2022-11-21T14:21:31.904193Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# class LivenessDataset(Dataset):\n#     def __init__(self, df, video_dir, take_frame = 5, transform=None):\n#         self.df = df.reset_index(drop = True)\n#         self.take_frame = take_frame\n#         self.video_dir = video_dir\n#         self.transform = transform\n\n#     def __len__(self):\n#         return len(self.df)\n\n#     def __getitem__(self, idx):\n#         fname = self.df.iloc[idx]['fname']\n#         video_path = os.path.join(self.video_dir, fname)\n#         video = cv2.VideoCapture(video_path)\n#         image_lst = []\n#         frame_number = 0\n#         length = int(video.get(cv2.CAP_PROP_FRAME_COUNT))\n#         frame_step = length // self.take_frame\n#         while video.isOpened():\n#             ret, frame = video.read()\n#             if ret:\n#                 frame_number += 1\n# #                 if frame is not None and frame_number % frame_step == 0:\n#                 if self.transform is not None:\n#                     frame = self.transform(image=frame)[\"image\"]\n#                 image_lst.append(frame)\n#                 if frame_number == 5:\n#                     break\n#             else:\n#                 break\n#         video.release()\n#         image_lst = image_lst[:self.take_frame]\n#         return torch.stack(image_lst, axis =0)","metadata":{"execution":{"iopub.status.busy":"2022-11-21T14:21:31.909937Z","iopub.execute_input":"2022-11-21T14:21:31.910810Z","iopub.status.idle":"2022-11-21T14:21:31.920850Z","shell.execute_reply.started":"2022-11-21T14:21:31.910777Z","shell.execute_reply":"2022-11-21T14:21:31.919942Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"class LivenessModel(torch.nn.Module):\n    def __init__(self, pretrained_name = 'resnet50'):\n        super(LivenessModel, self).__init__()\n        self.backbone = timm.create_model(pretrained_name, pretrained=None)\n        if pretrained_name == 'resnet50':\n            self.in_feats = self.backbone.fc.in_features\n            self.backbone.fc = torch.nn.Identity()\n        if pretrained_name == 'darknet53':\n            self.in_feats = self.backbone.head.fc.in_features\n            self.backbone.head.fc = torch.nn.Identity()\n    \n        self.lstm = torch.nn.LSTM(self.in_feats, self.in_feats, 2,\n                                  bidirectional = True, dropout = 0.3, batch_first = True)\n        self.linear = torch.nn.Linear(self.in_feats * 2, 1)\n    def forward(self, x):\n        b, f, c, h, w = x.shape\n        x = torch.reshape(x, (b * f, c, h, w))\n        x = self.backbone(x)\n        x = torch.reshape(x, (b, f, self.in_feats))\n        output, (h, c) = self.lstm(x)\n        x = output[:,-1,:]\n        x = self.linear(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2022-11-21T14:21:31.927186Z","iopub.execute_input":"2022-11-21T14:21:31.927499Z","iopub.status.idle":"2022-11-21T14:21:31.943614Z","shell.execute_reply.started":"2022-11-21T14:21:31.927470Z","shell.execute_reply":"2022-11-21T14:21:31.941955Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"pbl_test_dataset = LivenessDataset(submission, PUBLIC_TEST_PATH, take_frame = 5, transform = valid_transform)","metadata":{"execution":{"iopub.status.busy":"2022-11-21T14:21:31.944809Z","iopub.execute_input":"2022-11-21T14:21:31.945393Z","iopub.status.idle":"2022-11-21T14:21:31.961325Z","shell.execute_reply.started":"2022-11-21T14:21:31.945360Z","shell.execute_reply":"2022-11-21T14:21:31.960378Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"def infer_fn(model, dataloader, device):\n    \n    model.eval()\n    pred_lst, time_lst = [], []\n    with torch.no_grad():\n        for i, batch in tqdm(enumerate(dataloader)):\n            start = time.time()\n            inp = batch\n            inp = inp.to(device)\n            output = model(inp)\n            \n            np_output = output.detach().cpu().numpy()\n            pred_lst.append(np_output)\n            \n            del inp, output, np_output\n            torch.cuda.empty_cache()\n            gc.collect()\n            end = time.time()\n            time_lst.append(end - start)\n    pred = np.concatenate(pred_lst, axis = 0)\n    \n    return pred, time_lst","metadata":{"execution":{"iopub.status.busy":"2022-11-21T14:21:31.963061Z","iopub.execute_input":"2022-11-21T14:21:31.963844Z","iopub.status.idle":"2022-11-21T14:21:31.973644Z","shell.execute_reply.started":"2022-11-21T14:21:31.963810Z","shell.execute_reply":"2022-11-21T14:21:31.972405Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"test_dataloader = DataLoader(pbl_test_dataset, batch_size=VALID_BATCH_SIZE, shuffle=False)\nckpt = torch.load(ckpt_path)\nstate_dict = ckpt['state_dict']\nbest_eer = ckpt['eer']\nprint(best_eer)\nmodel = LivenessModel(backbone)\nmodel.load_state_dict(state_dict)\nmodel = model.to(DEVICE)","metadata":{"execution":{"iopub.status.busy":"2022-11-21T14:21:31.976908Z","iopub.execute_input":"2022-11-21T14:21:31.978188Z","iopub.status.idle":"2022-11-21T14:21:34.814932Z","shell.execute_reply.started":"2022-11-21T14:21:31.978141Z","shell.execute_reply":"2022-11-21T14:21:34.813946Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"0.0\n","output_type":"stream"}]},{"cell_type":"code","source":"sample = test_dataloader","metadata":{"execution":{"iopub.status.busy":"2022-11-21T14:21:34.816165Z","iopub.execute_input":"2022-11-21T14:21:34.816840Z","iopub.status.idle":"2022-11-21T14:21:34.823761Z","shell.execute_reply.started":"2022-11-21T14:21:34.816803Z","shell.execute_reply":"2022-11-21T14:21:34.822655Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"pred, time_lst = infer_fn(model, test_dataloader, DEVICE)\npred.shape","metadata":{"execution":{"iopub.status.busy":"2022-11-21T14:21:34.825308Z","iopub.execute_input":"2022-11-21T14:21:34.826445Z","iopub.status.idle":"2022-11-21T14:24:45.417201Z","shell.execute_reply.started":"2022-11-21T14:21:34.826411Z","shell.execute_reply":"2022-11-21T14:24:45.416101Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stderr","text":"486it [03:10,  2.55it/s]\n","output_type":"stream"},{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"(486, 1)"},"metadata":{}}]},{"cell_type":"code","source":"def sigmoid(x):\n    return 1 / (1 + np.exp(-x))","metadata":{"execution":{"iopub.status.busy":"2022-11-21T14:24:45.418836Z","iopub.execute_input":"2022-11-21T14:24:45.419228Z","iopub.status.idle":"2022-11-21T14:24:45.424910Z","shell.execute_reply.started":"2022-11-21T14:24:45.419192Z","shell.execute_reply":"2022-11-21T14:24:45.423591Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"pred = sigmoid(pred)","metadata":{"execution":{"iopub.status.busy":"2022-11-21T14:24:45.426697Z","iopub.execute_input":"2022-11-21T14:24:45.427146Z","iopub.status.idle":"2022-11-21T14:24:45.435940Z","shell.execute_reply.started":"2022-11-21T14:24:45.427110Z","shell.execute_reply":"2022-11-21T14:24:45.434648Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"submission['liveness_score'] = pred\nsubmission['predict_time'] = time_lst\nsubmission.to_csv('./submission.csv' ,index = False)","metadata":{"execution":{"iopub.status.busy":"2022-11-21T14:24:45.437319Z","iopub.execute_input":"2022-11-21T14:24:45.437936Z","iopub.status.idle":"2022-11-21T14:24:45.450608Z","shell.execute_reply.started":"2022-11-21T14:24:45.437900Z","shell.execute_reply":"2022-11-21T14:24:45.449649Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"submission.head(5)","metadata":{"execution":{"iopub.status.busy":"2022-11-21T14:24:45.451900Z","iopub.execute_input":"2022-11-21T14:24:45.452632Z","iopub.status.idle":"2022-11-21T14:24:45.467662Z","shell.execute_reply.started":"2022-11-21T14:24:45.452588Z","shell.execute_reply":"2022-11-21T14:24:45.466550Z"},"trusted":true},"execution_count":19,"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"     fname  liveness_score  predict_time\n0  123.mp4        0.000021      5.417344\n1  479.mp4        0.842261      0.222521\n2   28.mp4        0.995015      0.216825\n3  410.mp4        0.998569      0.217680\n4  408.mp4        0.002326      0.215135","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>fname</th>\n      <th>liveness_score</th>\n      <th>predict_time</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>123.mp4</td>\n      <td>0.000021</td>\n      <td>5.417344</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>479.mp4</td>\n      <td>0.842261</td>\n      <td>0.222521</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>28.mp4</td>\n      <td>0.995015</td>\n      <td>0.216825</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>410.mp4</td>\n      <td>0.998569</td>\n      <td>0.217680</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>408.mp4</td>\n      <td>0.002326</td>\n      <td>0.215135</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"submission","metadata":{"execution":{"iopub.status.busy":"2022-11-21T14:24:45.469851Z","iopub.execute_input":"2022-11-21T14:24:45.470810Z","iopub.status.idle":"2022-11-21T14:24:45.485392Z","shell.execute_reply.started":"2022-11-21T14:24:45.470775Z","shell.execute_reply":"2022-11-21T14:24:45.484044Z"},"trusted":true},"execution_count":20,"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"       fname  liveness_score  predict_time\n0    123.mp4        0.000021      5.417344\n1    479.mp4        0.842261      0.222521\n2     28.mp4        0.995015      0.216825\n3    410.mp4        0.998569      0.217680\n4    408.mp4        0.002326      0.215135\n..       ...             ...           ...\n481  217.mp4        0.943948      0.210051\n482  151.mp4        0.000016      0.214522\n483  135.mp4        0.004413      0.215135\n484   25.mp4        0.000033      0.215487\n485  361.mp4        0.023633      0.216973\n\n[486 rows x 3 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>fname</th>\n      <th>liveness_score</th>\n      <th>predict_time</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>123.mp4</td>\n      <td>0.000021</td>\n      <td>5.417344</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>479.mp4</td>\n      <td>0.842261</td>\n      <td>0.222521</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>28.mp4</td>\n      <td>0.995015</td>\n      <td>0.216825</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>410.mp4</td>\n      <td>0.998569</td>\n      <td>0.217680</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>408.mp4</td>\n      <td>0.002326</td>\n      <td>0.215135</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>481</th>\n      <td>217.mp4</td>\n      <td>0.943948</td>\n      <td>0.210051</td>\n    </tr>\n    <tr>\n      <th>482</th>\n      <td>151.mp4</td>\n      <td>0.000016</td>\n      <td>0.214522</td>\n    </tr>\n    <tr>\n      <th>483</th>\n      <td>135.mp4</td>\n      <td>0.004413</td>\n      <td>0.215135</td>\n    </tr>\n    <tr>\n      <th>484</th>\n      <td>25.mp4</td>\n      <td>0.000033</td>\n      <td>0.215487</td>\n    </tr>\n    <tr>\n      <th>485</th>\n      <td>361.mp4</td>\n      <td>0.023633</td>\n      <td>0.216973</td>\n    </tr>\n  </tbody>\n</table>\n<p>486 rows Ã— 3 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}